# -*- coding: utf-8 -*-
"""face detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BAa60_5KbYZJgfMM4UBDEO8fJekdlNBl
"""

!pip install opencv-python-headless
!pip install opencv-python
!pip install opencv-python-headless
!pip install numpy

!wget https://github.com/opencv/opencv/raw/master/samples/dnn/face_detector/deploy.prototxt
!wget https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel

"""Face Detection"""

import cv2
import numpy as np

# Load a pre-trained deep learning face detector (e.g., OpenCV's DNN module with the Caffe model)
model = cv2.dnn.readNetFromCaffe("/content/deploy.prototxt", "/content/res10_300x300_ssd_iter_140000.caffemodel")

# Load an image or video
image = cv2.imread("/content/Babar Azam.jpg")
(h, w) = image.shape[:2]

# Preprocess the image for face detection
blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))

# Pass the blob through the network to perform face detection
model.setInput(blob)
detections = model.forward()

# Loop over the detections and draw rectangles around the detected faces
for i in range(0, detections.shape[2]):
    confidence = detections[0, 0, i, 2]

    if confidence > 0.5:
        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
        (startX, startY, endX, endY) = box.astype("int")

        cv2.rectangle(image, (startX, startY), (endX, endY), (0, 255, 0), 2)

# Display the image with detected faces
# Display the image with detected faces
from google.colab.patches import cv2_imshow
cv2_imshow(image)

"""Face Recogination"""

!pip install facenet-pytorch
!pip install scikit-learn

!pip install facenet-pytorch

import cv2
from facenet_pytorch import InceptionResnetV1
import torch
from PIL import Image

# Load the pre-trained face recognition model
model = InceptionResnetV1(pretrained="vggface2").eval()

# Define known image paths and labels
known_image_paths = ['/content/babar.jpg', '/content/shaheen.jpg', '/content/fakhar.jpg']
labels = ['Babar', 'Shaheen', 'Fakhar']

# Function to preprocess an image
def preprocess_image(image_path):
    image = Image.open(image_path).convert('RGB')  # Open and convert to RGB
    image = image.resize((160, 160))  # Resize to model input size
    image = torch.tensor(np.array(image), dtype=torch.float32)  # Convert to tensor
    image = image.permute(2, 0, 1).unsqueeze(0)  # Adjust dimensions for model
    return (image - 127.5) / 128.0  # Normalize the image

# Compute embeddings for known faces
known_faces = []

for image_path in known_image_paths:
    image = preprocess_image(image_path)

    with torch.no_grad():
        face_embedding = model(image).numpy()

    known_faces.append(face_embedding)

# Load and preprocess the unknown image
unknown_image_path = '/content/babar.jpg'
unknown_image = preprocess_image(unknown_image_path)

# Compute the embedding for the unknown face
with torch.no_grad():
    unknown_face_embedding = model(unknown_image).numpy()

# Compare the unknown face embedding to known faces and recognize
distances = [np.linalg.norm(unknown_face_embedding - known_face) for known_face in known_faces]

# Set a threshold for recognition
threshold = 0.6

# Find the closest known face
min_distance = min(distances)

if min_distance < threshold:
    label = labels[distances.index(min_distance)]
    print(f"Recognized as: {label}")
else:
    print("Unknown face")